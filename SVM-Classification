

rm(list=ls())

# Load the library
install.packages("doMC")
install.packages("DMwR")
library(AUC)
library(caret)
library(CrossValidate)
library(cvTools)
library(devtools)
library(doMC)
library(doParallel)
library(DMwR)
library(e1071)
library(elasticnet)
library(foreach)
library(plotly)
library(pROC)
library(PRROC)
library(R.utils)
library(ROCR)
library(ROSE)
library(rminer)
library(ggplot2)
library(grid)
library(lattice)
library(MASS)
library(neuralnet)
library(nnet)
library(iterators)
library("foreach")
library("doParallel")
library(doMC)

#### Install Data ####

data_used # name of the data used for the study

output<-"Output_class" # the name of the output

# Create a function to write the classification results and variable importance measurements in the same list
multiResultClass <- function(result1=NULL,result2=NULL)
{me <- list(
  result1 = result1,
  result2 = result2)
#Set the name for the class
class(me) <- append(class(me),"multiResultClass")
return(me)}

# Create matrices to save the results during the cross-validation process
result_cross_validation<-matrix(ncol=13,nrow=10) 
result_cross_validation_100iteration<-NULL
var_imp_matrix<-NULL
predicted_output<-NULL

# Prepare the codes for the parallelisation
myCluster <- makeCluster(10)
registerDoMC(10)

# Turn 10 parallel program 10 times (different partition for each iteration)
result_parallel<-foreach(it=rep(1:10,10), .combine = rbind,.multicombine=TRUE,
                                                     .packages=c("nnet","rminer","caret","AUC","e1071")) %dopar% {cat(it)
                                                       
                                                       # Split the data in 10 partitions
                                                       
                                                       folds_outerloop<-createFolds(factor(data_used$Output_class),k=10,list = FALSE)                                                                   
                                                       
                                                       # Start the outer loop of the nested CV
                                                       
                                                       for(outerloop in 1:10){
                                                         
                                                         # Create a train dataset using 9 partitions over 10 
                                                         trainData <- data_used[folds_outerloop != outerloop, ]
                                                         
                                                         # Create a test dataset using 1 partition over 10  
                                                         
                                                         testData <- data_used[folds_outerloop == outerloop, ]
                                                         
                                                         # loop to chose best hyperparameters
                                                         
                                                         error_innerloop<-matrix(NA,ncol=3,nrow=25)
                                                         k=1
                                                         for (gamma1 in seq(0.1,1,0.1)) {
                                                           for (cost1 in 2^(0:9)) {
                                                             
                                                             err_cv<-matrix(ncol=2,nrow=10) 
                                                             err_cv1<-NULL
                                                             
                                                             # Repeat CV 10 times for different partitions
                                                             for (iterinner in 1:10) {
                                                               
                                                               # Create partitions from train dataset
                                                               folds_outerloop_inner<-createFolds(factor(trainData$Output_class),k=10,list = FALSE)
                                                               
                                                               for(innerloop in 1:10){
                                                                 
                                                                 trainingData <- trainData[folds_outerloop_inner != innerloop, ] 
                                                                 validationData <- trainData[folds_outerloop_inner == innerloop, ]
                                                                 
                                                                 # Normalize training dataset
                                                                 performScaling <- TRUE  # Turn it on/off for experimentation.
                                                                 
                                                                 if (performScaling) {
                                                                   
                                                                   # Loop over each column.
                                                                   for (colName in names(trainingData)) {
                                                                     
                                                                     # Check if the column contains numeric data.
                                                                     if(class(trainingData[,colName]) == 'integer' | class(trainingData[,colName]) == 'numeric') {
                                                                       
                                                                       # Scale this column (scale() function applies z-scaling).
                                                                       trainingData[,colName] <- as.numeric(scale(trainingData[,colName]))
                                                                     }
                                                                   }
                                                                 }
                                                                 
                                                                 library(DMwR)
                                                                 trainingData_smote <- SMOTE(Output_class ~ ., trainingData, perc.over = 100)
                                                                 
                                                                 # Fit the model using a couple of the hyperparameters
                                                                 innermodel_svm_prob<- svm(Output_class ~ .,  data = trainingData_smote,sigma=gamma1,
                                                                                           cost=cost1,probability=TRUE,kernel="radial",type="C-classification")
                                                                 
                                                                 # Load the library
                                                                 library(MASS)
                                                                 require(AUC)
                                                                 library(AUC)
                                                                 
                                                                 # Normalize the validation dataset using the information of training dataset
                                                                 normParam <- preProcess(trainingData_smote)
                                                                 norm.validationData <- predict(normParam, validationData)
                                                                 # Predict the validation dataset
                                                                 predict_validation_svm_prob<-predict(innermodel_svm_prob,norm.validationData,probability = TRUE)
                                                                 predict_validation_svm_prob2<-attr(predict_validation_svm_prob, "probabilities")[,2]
                                                                 err_cv[innerloop,1]<-innerloop
                                                                 err_cv[innerloop,2]<-auc(roc(response=norm.validationData$Output_class,predictor=predict_validation_svm_prob2,
                                                                                              plot=FALSE,direction="auto",quiet = TRUE))
                                                               }
                                                               err_cv1<-rbind(err_cv1,err_cv)
                                                             }
                                                           }
                                                           
                                                           # Decide the best hyperparameters based on AUC
                                                           mean_AUC_inner_10cv<-mean(err_cv1[,2],na.rm=TRUE)
                                                           error_innerloop[k,1]<-gamma1
                                                           error_innerloop[k,2]<-cost1
                                                           error_innerloop[k,3]<-mean_AUC_inner_10cv
                                                           
                                                           k=k+1
                                                         }
                                                         
                                                         # select the best hyperparameters that minimize the mean of AUC (over 10 iteration)
                                                         best_gamma<-error_innerloop[which.max(error_innerloop[,3]),1]
                                                         best_cost<-error_innerloop[which.max(error_innerloop[,3]),2]
                                                         
                                                         # Normalize the train dataset
                                                         library(DMwR)
                                                         # Normalize training dataset
                                                         performScaling <- TRUE  # Turn it on/off for experimentation.
                                                         
                                                         if (performScaling) {
                                                           
                                                           # Loop over each column.
                                                           for (colName in names(trainData)) {
                                                             
                                                             # Check if the column contains numeric data.
                                                             if(class(trainData[,colName]) == 'integer' | class(trainData[,colName]) == 'numeric') {
                                                               
                                                               # Scale this column (scale() function applies z-scaling).
                                                               trainData[,colName] <- as.numeric(scale(trainData[,colName]))
                                                             }
                                                           }
                                                         }
                                                         
                                                         # Balance the training dataset
                                                         trainData_SMOTE <- SMOTE(Output_class ~ ., trainData, perc.over = 100)
                                                         
                                                         # Fit the model with best hyperparameters using train data (PROBA)
                                                         tunedModel_prob<- svm(Output_class ~ .,  data = trainData_SMOTE,gamma=best_gamma,
                                                                               cost=best_cost,probability=TRUE,kernel="radial",type="C-classification")
                                                         
                                                         # Normalize the test dataset using the information of train dataset
                                                         normParam <- preProcess(trainData_SMOTE)
                                                         norm.testData <- predict(normParam, testData)
                                                         
                                                         # Predict the model using test data
                                                         tunedModelY_proba <- predict(tunedModel_prob, norm.testData,probability = TRUE) 
                                                         svm_predict_test_proba<-attr(tunedModelY_proba, "probabilities")[,2]
                                                         
                                                         # Calculate AUC
                                                         auc_test<-auc(roc(norm.testData$Output_class,svm_predict_test_proba,plot=FALSE,direction="auto",quiet = TRUE))
                                                         
                                                         # Predict the model using test data
                                                         svm_predict_test_class <- predict(tunedModel_prob, norm.testData,probability=FALSE) 
                                                         
                                                         # Confusion Matrix
                                                         library(caret)
                                                         result <- confusionMatrix(svm_predict_test_class,norm.testData$Output_class,positive="1")
                                                         
                                                         result_cross_validation[outerloop,1]<-best_gamma
                                                         result_cross_validation[outerloop,2]<-best_cost
                                                         result_cross_validation[outerloop,3]<-outerloop
                                                         result_cross_validation[outerloop,4]<-auc_test
                                                         
                                                         result_cross_validation[outerloop,5]<-result$byClass['Balanced Accuracy']
                                                         result_cross_validation[outerloop,6]<-result$byClass['Sensitivity']
                                                         result_cross_validation[outerloop,7]<-result$byClass['Specificity']
                                                         result_cross_validation[outerloop,8]<-result$byClass['Precision']
                                                         result_cross_validation[outerloop,9]<-result$byClass['Recall']
                                                         result_cross_validation[outerloop,10]<-result$byClass['F1']
                                                         result_cross_validation[outerloop,11]<-result$byClass['Balanced Accuracy']
                                                         result_cross_validation[outerloop,12]<-result$byClass['Pos Pred Value']
                                                         result_cross_validation[outerloop,13]<-result$byClass['Neg Pred Value']
                                                         
                                                         #  Variable Importance                                                  
                                                         M <- fit(Output_class~., data=trainData_SMOTE, model="svm", C=best_cost)
                                                         svm.imp <- Importance(M, data=trainData_SMOTE,measure = "range")
                                                         var_imp_matrix<-rbind(var_imp_matrix,as.data.frame(svm.imp$value))
                                                         
                                                         # Predicted and output
                                                         predicted_proba<-svm_predict_test_proba
                                                         predicted_class<-as.data.frame(svm_predict_test_class)
                                                         output<-as.data.frame(norm.testData$Output_class)
                                                         predicted_output<-rbind(predicted_output,cbind(predicted_proba,predicted_class,output,seq(1,dim(predicted_class)[1],1)))
                                                         
                                                       }
                                                       
                                                       # Save the results for 100 iterations
                                                       result_cross_validation_100iteration<-rbind(result_cross_validation_100iteration,result_cross_validation)
                                                       
                                                       result <- multiResultClass()
                                                       result$result1 <- result_cross_validation_100iteration
                                                       result$result2 <- var_imp_matrix
                                                       return(result)
                                                     }

